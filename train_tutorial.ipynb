{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771b51d0",
   "metadata": {},
   "source": [
    "2022-04-15 이주형\n",
    "\n",
    "https://github.com/pytorch/examples/tree/main/imagenet\n",
    "를 바탕으로 수정함.\n",
    "\n",
    "파이토치의 코드는 많은 경우에 위의 코드를 바탕으로 수정되므로 신뢰할 만하며 딥러닝의 내용을 모르면 어차피 이해가 어렵습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32162de",
   "metadata": {},
   "source": [
    "라이브러리 import 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from utils.scheduler import CosineAnnealingWarmUpSingle, CosineAnnealingWarmUpRestarts\n",
    "# import torchvision.models as models\n",
    "import model as models\n",
    "from utils.transforms import transforms_train, transforms_test, NormalizePerImage\n",
    "import math\n",
    "from utils.losses import *\n",
    "from utils import LARC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691605a5",
   "metadata": {},
   "source": [
    "## argument 파싱 부분\n",
    "\n",
    "* 설명하지 않은 부분은 안 건드리면 됩니다.\n",
    "\n",
    "args.model_version: EfficientNet, MobileNet, ResNet이 가능.\\\n",
    "args.workers: data I/O처리시 multi-processing 의 병렬 갯수 부분.\\\n",
    "args.epochs: 훈련 에폭\\\n",
    "args.batch_size: 미니배치 사이즈\\\n",
    "args.lr: 시작 러닝레잇\\\n",
    "args.momentum: 안건드리면 됩니다. SGD의 모멘텀 지수.\\\n",
    "args.wd: weight decay (l2 penalty term) 지수 부분.\\\n",
    "args.resume: 웨이트파일로부터 훈련할 경우 웨이트파일 (pth파일)의 경로를 명시\\\n",
    "args.seed: 재현성을 위한 seed.\\\n",
    "args.gpu: GPU 번호 (GPU 하나 쓸 경우 명시하세요)\\\n",
    "args.batch_loss: 포컬로스와 크로스 엔트로피 선택 가능 (기본이 포컬로스)\\\n",
    "args.scheduler: 러닝레잇 스케쥴러. 안건드리면 됩니다.\\\n",
    "args.num_categories: 클래스 갯수입니다. 건드리지 않으면 디폴트는 aihub 데이터셋에 맞게 7로 되어있습니다.\\\n",
    "args.multiprocessing_distributed: PyTorch의 DDP부분입니다. 모르면 내버려 두면 됩니다.\\\n",
    "args.identifier: ***이건 돌릴때마다 변경해주셔야 합니다. 생성 파일명입니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch FER Training')\n",
    "# parser.add_argument('data', metavar='DIR',\n",
    "#                     help='path to dataset')\n",
    "parser.add_argument('--model-version', metavar='ARCH', default='mobilenet_v3_small',\n",
    "                    choices=['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl', 'mobilenet_v3_large', 'mobilenet_v3_small', 'resnet18', 'resnet50'],\n",
    "                    help='model architecture')\n",
    "parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=100, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=32, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 128), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "#parser.add_argument('-b', '--batch-size', default=32, type=int,\n",
    "#                    metavar='N',\n",
    "#                    help='mini-batch size (default: 32), this is the total '\n",
    "#                         'batch size of all GPUs on the current node when '\n",
    "#                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-5, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--seed', default=1, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=0, type=int,\n",
    "                    help='GPU id to use.')\n",
    "parser.add_argument('--batch-loss', metavar='LOSS_TYPE', type= str, default='FL',\n",
    "                    choices=['CE', 'FL'])\n",
    "parser.add_argument('--if-momentum-scheduler', action='store_true', help='If use momentum scheduler')\n",
    "parser.add_argument('--scheduler', default='single', choices=[None, 'single', 'multi'], help='scheduler type. None for no scheduler.')\n",
    "parser.add_argument('--num-categories', default=7, type=int, help='number of categories (default: 7)')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')\n",
    "parser.add_argument('--identifier', default='ex', help='identifier to be used.')\n",
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf5511",
   "metadata": {},
   "source": [
    "PyTorch의 DistributedDataParallel과 관련된 부분이며 무시해도 됩니다.\\\n",
    "args.multiprocessing_distributed 의 default가 False이고 이렇게 되면 GPU와 컴퓨터를 하나만 사용하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        main_worker(args.gpu, ngpus_per_node, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e7e72",
   "metadata": {},
   "source": [
    "GPU 사용방식은 크게 3가지가 있습니다:\n",
    "1) 특정 GPU 사용: args.gpu 에 gpu 번호를 넣어주고 args.distributed를 toggle 하지 않음\n",
    "2) DatalParallel: args.gpu 에 gpu 번호를 명시하지 않고 args.distributed를 toggle 하지 않음\n",
    "3) DistributedDataParallel: args.distributed 를 toggle 함\n",
    "\n",
    "잘 모르면 args.gpu에서 gpu번호를 명시해줘서 gpu를 하나만 사용 (예: python train.py --gpu 0)\\\n",
    "CPU 사용 옵션은 없습니다. 사용할 GPU로 모델을 카피."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "\n",
    "    if args.distributed:\n",
    "        if args.dist_url == \"env://\" and args.rank == -1:\n",
    "            args.rank = int(os.environ[\"RANK\"])\n",
    "        if args.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "    # create model\n",
    "    print(\"=> creating model '{}'\".format(args.model_version))\n",
    "    if 'eff' in args.model_version:\n",
    "        model = models.__dict__[args.model_version](num_classes = args.num_categories)\n",
    "    else:\n",
    "        model = models.__dict__[args.model_version](num_classes=args.num_categories, pretrained=True)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        print('using CPU, this will be slow')\n",
    "    elif args.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        if args.model_version.startswith('alexnet') or args.model_version.startswith('vgg'):\n",
    "            model.features = torch.nn.DataParallel(model.features)\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af0212",
   "metadata": {},
   "source": [
    "args에 따른 로스함수의 선택과 이를 명시된 gpu로 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa646ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define loss function (criterion) and optimizer\n",
    "    if args.batch_loss == 'CE':\n",
    "        criterion = CrossEntropyLoss().cuda(args.gpu)\n",
    "    elif args.batch_loss == 'FL':\n",
    "        criterion = FocalLoss().cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c207a4",
   "metadata": {},
   "source": [
    "최적화 부분. SGD에 weight decay(l2 penalty)를 더한다.\\\n",
    "SGD를 LARS로 wrapping 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93d24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    _optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    optimizer = LARC(_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb93290",
   "metadata": {},
   "source": [
    "웨이트파일로부터 훈련하는 경우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "            else:\n",
    "                # Map model to be loaded to specified single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_acc1 = checkpoint['best_acc1']\n",
    "            if args.gpu is not None:\n",
    "                # best_acc1 may be from a checkpoint from a different GPU\n",
    "                best_acc1 = best_acc1.to(args.gpu)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            _optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b1700",
   "metadata": {},
   "source": [
    "cudnn.benchmark: 속도가 빨라지지만 재현성이 없어짐\\\n",
    "\n",
    "training set과 test set의 위치 설정\\\n",
    "\n",
    "PyTorch의 Data I/O 부분은 크게 Dataset과 DataLoader부분으로 나뉨.\\\n",
    "\n",
    "training set, validation set, test set에 대하여 각각 Dataset과 Dataloader를 만들어주는 부분.\\\n",
    "training set의 90%를 training set으로 사용하고 나머지 10%는 validation set으로 사용.\\\n",
    "training set에 대해서만 데이터의 셔플을 수행하고 나머지 셋에 대해서는 shuffle은 수행하지 않음\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # cudnn.benchmark = True\n",
    "\n",
    "    # Data loading code\n",
    "    # traindir = os.path.join(args.data, 'train')\n",
    "    # testdir = os.path.join(args.data, 'test')\n",
    "    traindir = os.path.join('data/train')\n",
    "    testdir = os.path.join('data/test')\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms_train())\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "\n",
    "    random.seed(args.seed)\n",
    "    random.shuffle(train_dataset.samples)\n",
    "    # training set의 90%를 training set으로 사용하고 나머지 10%는 validation set으로 사용.\n",
    "    num_val = int(0.1*len(train_dataset))\n",
    "    num_tr = int(len(train_dataset) - num_val)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [num_tr, num_val], generator=torch.Generator().manual_seed(args.seed))\n",
    "    val_dataset.transform = transforms_test()\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(testdir, transforms_test()),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=False, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd555a4",
   "metadata": {},
   "source": [
    "learning rate scheduler 부분.\\\n",
    "Simclr로 부터 시작된 방식을 차용했음: 시작 5% 에폭동안은 linear warm-up, 95% 동안은 cosine decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.scheduler == 'multi':\n",
    "        scheduler = CosineAnnealingWarmUpRestarts(_optimizer, eta_max=args.lr * math.sqrt(args.batch_size),\n",
    "                                                  step_total=len(train_loader) * args.epochs)\n",
    "    #            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(_optimizer, len(loader_tr_cv) * (args.epoch_steps[-1] - args.epoch_steps[0]), eta_min=0)\n",
    "    elif args.scheduler == 'single':\n",
    "        scheduler = CosineAnnealingWarmUpSingle(_optimizer, max_lr=args.lr * math.sqrt(args.batch_size),\n",
    "                                                epochs=args.epochs, steps_per_epoch=len(train_loader),\n",
    "                                                div_factor=math.sqrt(args.batch_size),\n",
    "                                                cycle_momentum=args.if_momentum_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP-16 의 mixed-precision 훈련\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    val_acc_list=[]\n",
    "    epoch_best = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2853325",
   "metadata": {},
   "source": [
    "에폭별로 looping 실행\\\n",
    "매 에폭마다 validation 정확도를 구해서 acc1에 저장\\\n",
    "현재까지중 가장 높았던 validation 정확도보다(best_acc1) 높다면 1) is_best flag 가 켜지고, 2) best_acc1이 바뀌고, 3) 모델이 ```f'{args.identifier}_model_best.pth.tar'```로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4aab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, scheduler, scaler, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_loader, model, criterion, args)\n",
    "        val_acc_list.append(acc1)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "                and args.rank % ngpus_per_node == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.model_version,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'optimizer' : _optimizer.state_dict(),\n",
    "            }, is_best, args)\n",
    "        if is_best:\n",
    "            epoch_best = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc8833",
   "metadata": {},
   "source": [
    "모든 훈련이 끝난 뒤 (디폴트: 100에폭), 100에폭중 validation 정확도가 가장 높았던 모델인 ```f'{args.identifier}_model_best.pth.tar'```를 불러옴\\\n",
    "불러온 뒤, test set에 테스트를 하여 test 정확도를 계산하고 이를 f\"{args.identifier}.txt\"에 저장함.\\\n",
    "또한 arg세팅을 ```f\"settings_{args.identifier}.txt\"```에 저장함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'{args.identifier}_model_best.pth.tar')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    # evaluate on test set\n",
    "    acc_test = validate(test_loader, model, criterion, args)\n",
    "\n",
    "    with open(os.path.join(f\"{args.identifier}.txt\"), 'w') as f:\n",
    "        f.write(f'test acc (%): {acc_test}\\n')\n",
    "        f.write(f'best val acc (%): {best_acc1}\\n')\n",
    "        f.write(f'best epoch: {epoch_best}\\n\\n')\n",
    "        f.write(f'val history: {val_acc_list}\\n')\n",
    "\n",
    "    with open(os.path.join(f\"settings_{args.identifier}.txt\"), 'w') as f:\n",
    "        f.write(f'args: {args}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f2475",
   "metadata": {},
   "source": [
    "## 훈련 함수\n",
    "훈련 모드로 바꾸고 (batch normalization, drop out 등의 사용세 변경),\\\n",
    "train set dataloader에서 미니배치를 하나씩 for loop을 통해 입력 받는다\\\n",
    "영상과 정답지를 gpu에 카피해주고, FP16상태에서 Feed-Forward와 로스를 계산한다.\\\n",
    "weight 벡터의 gradient 벡터를 0으로 바꿔주고, 로스를 통해 back propagation을 수행한 뒤, optimizer를 통해 weight의 업데이트를 수행.\\\n",
    "learning rate scheduler 또한 한 에폭이 끝났다고 알려줌 (learning rate을 변경시켜야 하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68253f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, scheduler, scaler, args):\n",
    "    # batch_time = AverageMeter('Time', ':6.3f')\n",
    "    # data_time = AverageMeter('Data', ':6.3f')\n",
    "    # losses = AverageMeter('Loss', ':.4e')\n",
    "    # top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # progress = ProgressMeter(\n",
    "    #     len(train_loader),\n",
    "    #     [batch_time, data_time, losses, top1],\n",
    "    #     prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    # end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        # data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        #  FP-16 사용\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        # acc1, _ = accuracy(output, target, topk=(1, 5))\n",
    "        # losses.update(loss.item(), images.size(0))\n",
    "        # top1.update(acc1[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        # batch_time.update(time.time() - end)\n",
    "        # end = time.time()\n",
    "\n",
    "        # if i % args.print_freq == 0:\n",
    "        #     progress.display(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005cc83",
   "metadata": {},
   "source": [
    "## validation/test 함수\n",
    "eval 모드로 바꾸고 (batch normalization, drop out 등의 사용세 변경) gradient 계산을 하지 않게 바꿈\\\n",
    "train set dataloader에서 미니배치를 하나씩 for loop을 통해 입력 받는다\\\n",
    "영상과 정답지를 gpu에 카피해주고, FP16상태에서 Feed-Forward만 수행한다.\\\n",
    "그라디언트 업데이트가 필요 없기 때문에 로스나 gradient관련 모든 task는 수행하지 않지만 대신 Feed-Forward에서 나온 logit을 바탕으로 확률값을 계산\\\n",
    "iteration 별로 정확도를 계산하며 이를 ```top1.update(acc1[0], images.size(0))```를 통해 append시키고 ```top1.avg.item()```를 통해 평균 한다.\n",
    "\n",
    "acc1: top-1 accuracy\\\n",
    "acc2: top-2 accuracy 지만 사용하지 않는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a71633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    # batch_time = AverageMeter('Time', ':6.3f')\n",
    "    # losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # compute output\n",
    "                output = model(images)\n",
    "                # loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc2 = accuracy(output, target, topk=(1, 2))\n",
    "            # losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            # batch_time.update(time.time() - end)\n",
    "            # end = time.time()\n",
    "\n",
    "            # if i % args.print_freq == 0:\n",
    "            #     progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    return top1.avg.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d819b46",
   "metadata": {},
   "source": [
    "웨이트 파일 생성 부분입니다.\\\n",
    "```is_best``` flag가 켜졌을 때만 ```f'{args.identifier}_model_best.pth.tar'```의 이름으로 웨이트파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34206133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, args):\n",
    "    # torch.save(state, f'{args.identifier}_checkpoint.pth.tar')\n",
    "    if is_best:\n",
    "        torch.save(state, f'{args.identifier}_model_best.pth.tar')\n",
    "        # shutil.copyfile(f'{args.identifier}_checkpoint.pth.tar', f'{args.identifier}_model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f632a",
   "metadata": {},
   "source": [
    "저도 건드리지 않았지만 정확도 계산 부분입니다. 호기심 이외의 목적으로는 고칠 필요도 없고 볼 필요도 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4191ad2",
   "metadata": {},
   "source": [
    "본 파일을 메인 함수로 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
