{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a688e6",
   "metadata": {},
   "source": [
    "2022-04-15 이주형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaceda64",
   "metadata": {},
   "source": [
    "라이브러리 import 부분\n",
    "https://github.com/timesler/facenet-pytorch   의 MTCNN을 utils/facenet_pytorch    에 저장해두어서 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import glob\n",
    "import os\n",
    "from facenet_pytorch import MTCNN\n",
    "import argparse\n",
    "import torch\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864858a",
   "metadata": {},
   "source": [
    "## argument 파싱 부분\n",
    "\n",
    "args.input: 이 path 바로 아래에 변환할 영상들이 저장되어있어야 함.\\\n",
    "args.output: 이 path 바로 아래에 변환된 영상들이 저장될 예정.\\\n",
    "args.file_type: ```args.input```아래에 저장된 영상들의 확장자\\\n",
    "args.num_process: file I/O에 사용될 multi-process 갯수\\\n",
    "args.image_size: MTCNN이 얼굴을 인식하여 ```args.image_size```에 맞게 resize를 수행하여 return합니다.\\\n",
    "args.face_margin: MTCNN 얼굴을 return할 때, 얼굴 사면에 ```args.face_margin```만큼의 margin을 두고 return합니다.\\\n",
    "args.hierarchy_level: 1이면 ```args.input```바로 아래에 영상이 있어야 하고, 2 이면 ```args.input```바로 아래에 폴더들이 있고 그 아래에 영상들이 있어야 합니다.\\\n",
    "args.gpu: 사용할 gpu 번호\\\n",
    "args.num_images:\n",
    "1) 양수:\n",
    " ```args.input``` 아래의 영상들의 순서를 셔플 뒤, 앞에서부터 ```args.num_images``` 만큼의 영상에서 얼굴을 추출함\n",
    "2) 음수:\n",
    " ```args.input``` 아래의 영상들의 순서를 셔플 뒤, 뒤에서부터 ```args.num_images``` 만큼의 영상에서 얼굴을 추출함\n",
    "3) 양수:\n",
    " ```args.input``` 아래의 영상들의 순서를 셔플 뒤, 전부 얼굴을 추출함\n",
    " \n",
    "args.seed: 재현성을 위한 seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Extract face portion and save')\n",
    "parser.add_argument('--input', default='../data/raw_images_eng/ANGRY', help='directory where raw images are saved')\n",
    "parser.add_argument('--output', default='../data/face_images_eng/ANGRY', help='directory where cropped images will be saved')\n",
    "parser.add_argument('--file-type', default='jpg', type=str, help='file type, e.g., jpg')\n",
    "parser.add_argument('--num-process', default=16, type=int, help='number of process')\n",
    "parser.add_argument('--image-size', default=160, type=int, help='size of extracted face image')\n",
    "parser.add_argument('--face-margin', default=15, type=int, help='additional spatial margin around face')\n",
    "parser.add_argument('--hierarchy-level', default=1, type=int, help='hierarchy level of files saved')\n",
    "parser.add_argument('--gpu', default=0, type=int, help='hierarchy level of files saved')\n",
    "parser.add_argument('--num-images', default=0, type=int, help='number of images to use per emotion category. Max: 7000')\n",
    "parser.add_argument('--seed', default=3, type=int, help='seed for shuffle')\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596c467",
   "metadata": {},
   "source": [
    "```args.output```폴더를 지우고 다시 만듬 (***조심!!!***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f96183",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if os.path.isdir(args.output):\n",
    "        shutil.rmtree(args.output)\n",
    "\n",
    "    os.mkdir(args.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48fa09",
   "metadata": {},
   "source": [
    "```args.face_margin```만큼의 마진을 두고 얼굴을 추출하여 ```args.image_size```사이즈로 resize한 뒤, ```args.gpu```로 카피하는 MTCNN을 instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53799e18",
   "metadata": {},
   "outputs": [],
   "source": [
    " mtcnn = MTCNN(image_size=args.image_size, margin=args.face_margin, device=torch.device(f'cuda:{args.gpu}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8fd77",
   "metadata": {},
   "source": [
    "```path```에서 영상을 읽어서 (```cv2.imread()```), 영상이 정상이라면 (```if img is not None```) 영상을 BGR에서 RGB로 변환한다 (cv2.는 BGR로 읽는데, 모델은 rgb기준으로 훈련되어 있을 것이기 때문).\\\n",
    "cuda에서 버퍼를 날리고 ```mtcnn```으로 ```args.output```에 저장하는 함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extract_and_save(path, args=args):\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        # 중요!!\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            _ = mtcnn(img, path.replace(args.input, args.output))\n",
    "        except Exception as e:\n",
    "            print(f'{os.path.basename(path)} : {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e5fa5",
   "metadata": {},
   "source": [
    "```args.input```에서 영상들을 읽어옵니다.\n",
    "seed와 셔플은 없어도 됩니다. 전부가 아닌 몇개만 뽑아올때, 영상의 순서가 비슷한 영상들이 몰려있기 때문에 shuffle을 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e742dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = glob.glob(args.input + ('/*' * args.hierarchy_level) + f'.{args.file_type}')\n",
    "    #pp.sort()\n",
    "    random.seed(args.seed)\n",
    "    random.shuffle(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fafda",
   "metadata": {},
   "source": [
    "위에서(```args```정의 부분) 설명한대로 ```args.num_images```에 따라 얼굴 추출 모드를 바꿔줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.num_images > 0:\n",
    "        print(f'Extracting faces from the first {args.num_images} images...')\n",
    "        pp = pp[:args.num_images]\n",
    "    elif args.num_images < 0:\n",
    "        print(f'Extracting faces from the last {args.num_images} images...')\n",
    "        pp = pp[args.num_images::]\n",
    "    elif args.num_images == 0:\n",
    "        print(f'Extracting faces from all images...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb163634",
   "metadata": {},
   "source": [
    "multi-threading 을 사용하여 얼굴을 추출하고 추출된 얼굴영상을 저장합니다.\\\n",
    "thread 갯수는 ```args.num_process```입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b105ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.num_process > 2:\n",
    "        #pass\n",
    "        pool = ThreadPool(processes=args.num_process)\n",
    "        pool.map(extract_and_save, (img_path for img_path in pp))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        for img_path in pp:\n",
    "            extract_and_save(img_path, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e0cb3",
   "metadata": {},
   "source": [
    "본 파일을 메인 함수로 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409de0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
